<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta property="og:image" content="https://priml-workshop.github.io/priml2019/img/preview-image.png" />
    <meta property="og:image:alt" content="Privacy in Machine Learning (PriML) NeurIPS 2019 Workshop" />
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Privacy in Machine Learning (NeurIPS 2019 Workshop)" />
    <meta name="twitter:image" content="https://priml-workshop.github.io/priml2019/img/twitter-img.png" />
    <meta name="twitter:image:alt" content="PriML Workshop" />
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Privacy in Machine Learning (NeurIPS 2019 Workshop)</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <link href="css/style.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">

    <!-- Navigation -->
    <nav class="navbar navbar-custom navbar-fixed-top">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-main-collapse">
                    Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top">
                    <span class="light">P<span style="text-transform:lowercase">ri</span>ML'19</span>
                </a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse navbar-right navbar-main-collapse">
                <ul class="nav navbar-nav">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#about">Scope</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#dates">CFP &amp Dates</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#speakers">Invited Speakers</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#schedule">Schedule</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#papers">Accepted Papers</a>
                    </li>
                    <!-- <li>
                        <a class="page-scroll" href="#grants">Travel Grants</a>
                    </li> -->
                    <li>
                        <a class="page-scroll" href="#organizers">Organizers</a>
                    </li>
                    <li>
                      <a class="page-scroll" href="#access">Accessibility</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Intro Header -->
    <header class="intro">
        <div class="intro-body">
            <div class="container">
                <div class="row">
                    <div class="col-md-8 col-md-offset-2">
                        <h1 class="brand-heading">Privacy in Machine Learning</h1>
                        <p class="intro-text">
                            <a href="https://neurips.cc/" style="color:white">NeurIPS 2019</a> Workshop
                            <br />Vancouver, December 14
                        </p>
                        <!--<p class="location-text">
                            Palais des Congrès de Montréal
                            <br /> Room: 512CDGH
                        </p>-->
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- About Section -->
    <section id="about" class="container content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>Scope</h2>

                  <p>The goal of our workshop is to bring together privacy experts working in academia and
                  industry to discuss the present and the future of privacy-aware technologies powered by
                  machine learning. The workshop will focus on the technical aspects of privacy research and
                  deployment with invited and contributed talks by distinguished researchers in the area.
                  We encourage submissions exploring a broad range of research areas related to data privacy,
                  including but not limited to:</p>

                  <ul class="list-group">
                      <li class="list-group-item speaker">Differential privacy: theory, applications, and implementations</li>
                      <li class="list-group-item speaker">Privacy-preserving machine learning</li>
                      <li class="list-group-item speaker">Trade-offs between privacy and utility</li>
                      <li class="list-group-item speaker">Programming languages for privacy-preserving data analysis</li>
                      <li class="list-group-item speaker">Statistical and information-theoretic notions of privacy</li>
                      <li class="list-group-item speaker">Empirical and theoretical comparisons between different notions of privacy</li>
                      <li class="list-group-item speaker">Privacy attacks</li>
                      <li class="list-group-item speaker">Policy-making aspects of data privacy</li>
                      <li class="list-group-item speaker">Secure multi-party computation techniques for machine learning</li>
                      <li class="list-group-item speaker">Learning on encrypted data, homomorphic encryption</li>
                      <li class="list-group-item speaker">Distributed privacy-preserving algorithms</li>
                      <li class="list-group-item speaker">Privacy in autonomous systems</li>
                      <li class="list-group-item speaker">Online social networks privacy</li>
                      <li class="list-group-item speaker">Interplay between privacy and adversarial robustness in machine learning</li>
                      <li class="list-group-item speaker">Relations between privacy, fairness and transparency</li>
                  </ul>
            </div>
        </div>
    </section>

    <!-- CFP & Dates Section -->
        <section id="dates" class="container content-section text-center">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2">
                    <h2>Call For Papers &amp; Important Dates</h2>
                    <a href="cfp-priml19.txt" class="btn btn-default btn-lg">Download Full CFP</a>
                    <br/>
                    <br/>
                    <br/>
                    <p>
                        <b>Submission deadline</b>: September 9, 2019, 23:59 UTC
                        <br/><b>Notification of acceptance</b>: October 1, 2019
                        <br/><b>NeurIPS early <a href="https://nips.cc/Conferences/2019/Press?article=2299">registration</a> deadline</b>: October 23, 2019
                        <br/><b>Workshop</b>: December 14, 2019 (Saturday)
                    </p>
                    <h3>Instructions</h3>
                      <p>
                        The submission deadline has now passed.
                        If your submission was accepted for a poster presentation,
                        please make your posters 36W x 48H inches or 90 x 122 cm.
                        Posters should be on light weight paper and should not be laminated.
                        As you design your poster,
                        you may find the following resource helpful:
                        <a href="resources/accessibility_posters_gilson2019.pdf">Guidelines for Creating Accessible Printed Posters</a>.

                      </p>
                    <!-- <a href="https://easychair.org/conferences/?conf=priml2019" class="btn btn-default btn-lg">Submit Your Abstract</a> -->
                    <br/>
                    <br/>
                    <br/>
                    <h3>Related Workshops</h3>
                        <p><b><a href="http://federated-learning.org/fl-neurips-2019/">Federated Learning for Data Privacy and Confidentiality</a> @ NeurIPS</b>: December 13, 2019</p>
                </div>
            </div>
        </section>

    <!-- Speakers Section -->
    <section id="speakers" class="container content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>Invited Speakers</h2>
                <ul class="list-group">
                    <li class="list-group-item speaker">Philip Leclerc (US Census)</li>
                    <li class="list-group-item speaker">Ashwin Machanavajjhala (Duke University)</li>
                    <li class="list-group-item speaker">Brendan McMahan (Google)</li>
                    <li class="list-group-item speaker">Lalitha Sankar (Arizona State University)</li>
                </ul>
            </div>
        </div>
    </section>

    <!-- Schedule Section -->
    <section id="schedule" class="container content-section text-center">
        <div class="row">
            <div class="col-sm-8 col-sm-offset-2">
                <h2>Schedule</h2>
                <table class="table schedule">
                    <tbody>
                    <tr>
                        <td class="time">8:10</td>
                        <td class="slot">Opening</td>
                    </tr>

                    <tr>
                        <td class="time">8:15</td>
                        <td class="slot talk">
                        Invited talk:
                        <a href="#tabs2" data-toggle="collapse" class="accordion-toggle">
                        Brendan McMahan
                        <!-- &mdash;
                        title -->
                        </a>&nbsp;&nbsp;
                        <!-- <a href="slides/slides.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs2">
                            More details coming soon
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">9:05</td>
                        <td class="slot talk"><a href="#tabs3" data-toggle="collapse" class="accordion-toggle">
                        Gaussian Differential Privacy
                        </a>
                        (contributed talk)
                        &nbsp;&nbsp;
                        <br/>
                        <span style="font-weight: normal">
                        Jinshuo Dong, Aaron Roth and Weijie Su
                        </span>
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs3">
                              Differential privacy has seen remarkable success as a rigorous and practical formalization of data privacy in the past decade.
                              This privacy definition and its divergence based relaxations, however, have several acknowledged weaknesses, either in handling composition of private algorithms or in analyzing important primitives like privacy amplification by subsampling.
                              Inspired by the hypothesis testing formulation of privacy, this paper proposes a new relaxation, which we term `f-differential privacy' (f-DP).
                              This notion of privacy has a number of appealing properties and, in particular, avoids difficulties associated with divergence based relaxations.
                              First, f-DP preserves the hypothesis testing interpretation.
                              In addition, f-DP allows for lossless reasoning about composition in an algebraic fashion.
                              Moreover, we provide a powerful technique to import existing results proven for original DP to f-DP and, as an application, obtain a simple subsampling theorem for f-DP.
                              In addition to the above findings, we introduce a canonical single-parameter family of privacy notions within the f-DP class that is referred to as `Gaussian differential privacy' (GDP),
                              defined based on testing two shifted Gaussians.
                              GDP is focal among the f-DP class because of a central limit theorem we prove.
                              More precisely, the privacy guarantees of any hypothesis testing based definition of privacy (including original DP) converges to GDP in the limit under composition.
                              The CLT also yields a computationally inexpensive tool for analyzing the exact composition of private algorithms.
                              Taken together, this collection of attractive properties render f-DP a mathematically coherent, analytically tractable, and versatile framework for private data analysis.
                              Finally, we demonstrate the use of the tools we develop by giving an improved privacy analysis of noisy stochastic gradient descent.
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">9:25</td>
                        <td class="slot talk"><a href="#tabs4" data-toggle="collapse" class="accordion-toggle">
                        QUOTIENT: Two-Party Secure Neural Network Training &amp; Prediction
                        </a>
                        (contributed talk)
                        &nbsp;&nbsp;
                        <br/>
                        <span style="font-weight: normal">
                        Nitin Agrawal, Ali Shahin Shamsabadi, Matthew Kusner and Adria Gascon
                        </span>
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs4">
                                Recently, there has been a wealth of effort devoted to the design of secure protocols for machine learning tasks.
                                Much of this is aimed at enabling secure prediction from highly-accurate Deep Neural Networks (DNNs).
                                However, as DNNs are trained on data, a key question is how such models can be also trained securely.
                                The few prior works on secure DNN training have focused either on designing custom protocols for existing training algorithms
                                or on developing tailored training algorithms and then applying generic secure protocols.
                                In this work, we investigate the advantages of designing training algorithms alongside a novel secure protocol, incorporating optimizations on both fronts.
                                We present QUOTIENT, a new method for discretized training of DNNs,
                                along with a customized secure two-party protocol for it.
                                QUOTIENT incorporates key components of state-of-the-art DNN training such as layer normalization and adaptive gradient methods,
                                and improves upon the state-of-the-art in DNN training in two-party computation.
                                Compared to prior work, we obtain an improvement of 50X in WAN time and 6&#37; in absolute accuracy.
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">9:45</td>
                        <td class="break">Coffee break</td>
                    </tr>

                    <tr>
                        <td class="time">10:30</td>
                        <td class="slot talk">
                        Invited talk:
                        <a href="#tabs5" data-toggle="collapse" class="accordion-toggle">
                        Ashwin Machanavajjhala
                        <!-- &mdash;
                        title -->
                        </a> &nbsp;&nbsp;
                        <!-- <a href="slides/chaudhuri.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs5">
                              More details coming soon
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">11:20</td>
                        <td class="slot talk"><a href="#tabs6" data-toggle="collapse" class="accordion-toggle">
                        Spotlight talks
                        </a> &nbsp;&nbsp;
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs6">
                            <ol>
                                <li>[Jonathan Lebensold, William Hamilton, Borja Balle and Doina Precup] Actor Critic with Differentially Private Critic (#08)</li>
                                <li>[Andres Munoz, Umar Syed, Sergei Vassilvitskii and Ellen Vitercik] Private linear programming without constraint violations (#17)</li>
                                <li>[Ios Kotsogiannis, Yuchao Tao, Xi He, Ashwin Machanavajjhala, Michael Hay and Gerome Miklau] PrivateSQL: A Differentially Private SQL Query Engine (#27)</li>
                                <li>[Amrita Roy Chowdhury, Chenghong Wang, Xi He, Ashwin Machanavajjhala and Somesh Jha] Crypt$\epsilon$: Crypto-Assisted Differential Privacy on Untrusted Servers (#31)</li>
                                <li>[Jiaming Xu and Dana Yang] Optimal Query Complexity of Private Sequential Learning (#32)</li>
                                <li>[Hsiang Hsu, Shahab Asoodeh and Flavio Calmon] Discovering Information-Leaking Samples and Features (#43)</li>
                                <li>[Martine De Cock, Rafael Dowsley, Anderson Nascimento, Davis Railsback, Jianwei Shen and Ariel Todoki] Fast Secure Logistic Regression for High Dimensional Gene Data (#44)</li>
                                <li>[Giuseppe Vietri, Grace Tian, Mark Bun, Thomas Steinke and Steven Wu] New Oracle-Efficient Algorithms for Private Synthetic Data Release (#45)</li>
                            </ol>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">11:30</td>
                        <td class="slot">Poster session</td>
                    </tr>

                    <tr>
                        <td class="time">12:30</td>
                        <td class="break">Lunch break</td>
                    </tr>

                    <tr>
                        <td class="time">14:00</td>
                        <td class="slot talk">
                        Invited talk:
                        <a href="#tabs7" data-toggle="collapse" class="accordion-toggle">
                        Lalitha Sankar
                        <!-- &mdash;
                        title -->
                        </a> &nbsp;&nbsp;
                        <!-- <a href="slides/smith.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs7">
                            More details coming soon
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">14:50</td>
                        <td class="slot talk"><a href="#tabs8" data-toggle="collapse" class="accordion-toggle">
                        Pan-Private Uniformity Testing
                        </a>
                        (contributed talk)
                        &nbsp;&nbsp;
                        <br/>
                        <span style="font-weight: normal">
                        Kareem Amin, Matthew Joseph and Jieming Mao
                        </span>
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs8">
                              More details coming soon
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">15:10</td>
                        <td class="slot talk"><a href="#tabs9" data-toggle="collapse" class="accordion-toggle">
                        Private Stochastic Convex Optimization: Optimal Rates in Linear Time
                        </a>
                        (contributed talk)
                        &nbsp;&nbsp;
                        <!-- <a href="slides/39.pdf" class="link-paper">[slides]</a> -->
                        <br/>
                        <span style="font-weight: normal">
                        Vitaly Feldman, Tomer Koren and Kunal Talwar
                        </span>
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs9">
                            More details coming soon
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">15:30</td>
                        <td class="break">Coffee break</td>
                    </tr>

                    <tr>
                        <td class="time">16:15</td>
                        <td class="slot talk">
                        Invited talk:
                        <a href="#tabs10" data-toggle="collapse" class="accordion-toggle">
                        Philip Leclerc
                        <!-- &mdash;
                        title -->
                        </a> &nbsp;&nbsp;
                        <!-- <a href="slides/chaudhuri.pdf" class="link-paper">[slides]</a> -->
                        </td>
                    </tr>
                    <tr>
                        <td colspan="2" class="hiddenRow">
                            <div class="accordion-body collapse talk-abstract" id="tabs10">
                            More details coming soon
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="time">17:05</td>
                        <td class="slot">Panel Discussion</td>
                    </tr>

                    <tr>
                        <td class="time">17:55</td>
                        <td class="slot">Closing</td>
                    </tr>

        		    </tbody>
        		</table>
            </div>
        </div>
    </section>

    <!-- Accepted Papers -->

    <section id="papers" class="container content-section text-center">
        <div class="row">
        <div class="col-lg-8 col-lg-offset-2">
            <h2>Accepted Papers</h2>
                <h4 style="color: #d07200;">
                Links to pdfs as well as abstracts will be added soon.
                </h4>

                <!-- <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            AUTHOTS
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs8" class="paper-title">
                            TITLE (paper with PDF)
                        </a> &nbsp;&nbsp;
                        <a href="papers/13.pdf" class="link-paper">[PDF]</a>
                    </div>
                    <div id="abs8" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        AUTHORS
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs1" class="paper-title">
                        TITLE (paper with Arvix link)
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1811.11124" class="link-paper">[arxiv]</a>
                    </div>
                    <div id="abs1" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div>
                </div>

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                            AUTHORS
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs11" class="paper-title">
                            TITLE (paper with contributed talk) <font color="#d07200"><b>(contributed talk)</b></font>
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1806.03287" class="link-paper">[arxiv]</a>
                    </div>
                    <div id="abs11" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div>
                </div> -->

                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Clément Canonne, Gautam Kamath, Audra McMillan, Jonathan Ullman and Lydia Zakynthinou
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs1" class="paper-title">
                        Private Identity Testing for High-Dimensional Distributions
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/pdf/1905.11947.pdf" class="link-paper">[arxiv]</a>
                    </div>
                    <div id="abs1" class="panel-footer panel-paper-footer collapse">
                    In this work we present novel differentially private identity (goodness-of-fit) testers for natural and widely studied classes of multivariate product distributions:
                    Gaussians in &#8477;<sup>d</sup> with known covariance and product distributions over {&plusmn;1}<sup>d</sup>.
                    Our testers have improved sample complexity compared to those derived from previous techniques,
                    and are the first testers whose sample complexity matches the order-optimal minimax sample complexity of O(d<sup>1/2</sup>&#47;&alpha;<sup>2</sup>) in many parameter regimes.
                    We construct two types of testers, exhibiting tradeoffs between sample complexity and computational complexity.
                    Finally, we provide a two-way reduction between testing a subclass of multivariate product distributions and testing univariate distributions,
                    and thereby obtain upper and lower bounds for testing this subclass of product distributions.
                    </div>
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                          Kwang-Sung Jun and Francesco Orabona
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs2" class="paper-title">
                        Parameter-Free Locally Differentially Private Stochastic Subgradient Descent
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1911.09564" class="link-paper">[arxiv]</a>
                    </div>
                    <div id="abs2" class="panel-footer panel-paper-footer collapse">
                    We consider the problem of minimizing a convex risk with stochastic subgradients guaranteeing &#x3F5;-locally differentially private (&#x3F5;-LDP).
                    While it has been shown that stochastic optimization is possible with &#x3F5;-LDP via the standard SGD (Song et al., 2013),
                    its convergence rate largely depends on the learning rate, which must be tuned via repeated runs.
                    Further, tuning is detrimental to privacy loss since it significantly increases the number of gradient requests.
                    In this work, we propose BANCO (Betting Algorithm for Noisy COins),
                    the first &#x3F5;-LDP SGD algorithm that essentially matches the convergence rate of the tuned SGD without any learning rate parameter,
                    reducing privacy loss and saving privacy budget.
                    </div>
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Seth Neel, Zhiwei Steven Wu, Aaron Roth and Giuseppe Vietri
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs3" class="paper-title">
                        Differentially Private Objective Perturbation: Beyond Smoothness and Convexity
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1909.01783" class="link-paper">[arxiv]</a>
                    </div>
                    <div id="abs3" class="panel-footer panel-paper-footer collapse">
                    One of the most effective algorithms for differentially private learning and optimization is objective perturbation.
                    This technique augments a given optimization problem (e.g. deriving from an ERM problem) with a random linear term,
                    and then exactly solves it.
                    However, to date, analyses of this approach crucially rely on the convexity and smoothness of the objective function.
                    We give two algorithms that extend this approach substantially.
                    The first algorithm requires nothing except boundedness of the loss function,
                    and operates over a discrete domain.
                    Its privacy and accuracy guarantees hold even without assuming convexity.
                    The second algorithm operates over a continuous domain and requires only that the loss function be bounded and Lipschitz in its continuous parameter.
                    Its privacy analysis does not even require convexity.
                    Its accuracy analysis does require convexity,
                    but does not require second order conditions like smoothness.
                    We complement our theoretical results with an empirical evaluation of the non-convex case,
                    in which we use an integer program solver as our optimization oracle.
                    We find that for the problem of learning linear classifiers,
                    directly optimizing for 0/1 loss using our approach can out-perform the more standard approach of privately optimizing a convex-surrogate loss function on the Adult dataset.
                    </div>
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Di Wang, Huanyu Zhang, Marco Gaboardi and Jinhui Xu
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs4" class="paper-title">
                        Estimating Smooth GLM in Non-interactive Local Differential Privacy Model with Public Unlabeled Data
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs4" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Liwei Song, Reza Shokri and Prateek Mittal
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs5" class="paper-title">
                        Privacy vs Robustness (against Adversarial Examples) in Machine Learning
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs5" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Jonathan Lebensold, William Hamilton, Borja Balle and Doina Precup
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs6" class="paper-title">
                        Actor Critic with Differentially Private Critic
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs6" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Samyadeep Basu, Rauf Izmailov and Chris Mesterharm
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs7" class="paper-title">
                        Membership Model Inversion Attacks for Deep Networks
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/pdf/1910.04257.pdf" class="link-paper">[arxiv]</a>
                    </div>
                    <div id="abs7" class="panel-footer panel-paper-footer collapse">
                    With the increasing adoption of AI,
                    inherent security and privacy vulnerabilities for machine learning systems are being discovered.
                    One such vulnerability makes it possible for an adversary to obtain private information about the types of instances used to train the targeted machine learning model.
                    This so-called model inversion attack is based on sequential leveraging of classification scores towards obtaining high confidence representations for various classes.
                    However, for deep networks, such procedures usually lead to unrecognizable representations that are useless for the adversary.
                    In this paper, we introduce a more realistic definition of model inversion,
                    where the adversary is aware of the general purpose of the attacked model
                    (for instance, whether it is an OCR system or a facial recognition system),
                    and the goal is to find realistic class representations within the corresponding lower-dimensional manifold
                    (of, respectively, general symbols or general faces).
                    To that end, we leverage properties of generative adversarial networks for constructing a connected lower-dimensional manifold,
                    and demonstrate the efficiency of our model inversion attack that is carried out within that manifold.
                    </div>
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Gautam Kamath, Janardhan Kulkarni, Zhiwei Steven Wu and Huanyu Zhang
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs8" class="paper-title">
                        Privately Learning Markov Random Fields
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs8" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Lovedeep Gondara and Ke Wang
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs9" class="paper-title">
                        Differentially Private Survival Function Estimation
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/pdf/1910.05108.pdf" class="link-paper">[arxiv]</a>
                    </div>
                    <div id="abs9" class="panel-footer panel-paper-footer collapse">
                    Survival function estimation is used in many disciplines,
                    but it is most common in medical analytics in the form of the Kaplan-Meier estimator.
                    Sensitive data (patient records) is used in the estimation without any explicit control on the information leakage,
                    which is a significant privacy concern.
                    We propose a first differentially private estimator of the survival function and
                    show that it can be easily extended to provide differentially private confidence intervals and test statistics
                    without spending any extra privacy budget.
                    We further provide extensions for differentially private estimation of the competing risk cumulative incidence function.
                    Using nine real-life clinical datasets,
                    we provide empirical evidence that our proposed method provides good utility while simultaneously providing strong privacy guarantees.
                    </div>
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Ang Li, Jiayi Guo, Huanrui Yang and Yiran Chen
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs10" class="paper-title">
                        DeepObfuscator: Adversarial Training Framework for Privacy-Preserving Image Classification
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/pdf/1909.04126.pdf" class="link-paper">[arxiv]</a>
                    </div>
                    <div id="abs10" class="panel-footer panel-paper-footer collapse">
                    Deep learning has been widely utilized in many computer vision applications and achieved remarkable commercial success.
                    However, running deep learning models on mobile devices is generally challenging due to limitation of the available computing resources.
                    It is common to let the users send their service requests to cloud servers that run the large-scale deep learning models to process.
                    Sending the data associated with the service requests to the cloud, however, impose risks on the user data privacy.
                    Some prior arts proposed sending the features extracted from raw data (e.g., images) to the cloud.
                    Unfortunately, these extracted features can still be exploited by attackers to recover raw images and to infer embedded private attributes (e.g., age, gender, etc.).
                    In this paper, we propose an adversarial training framework <i>DeepObfuscator</i> that can prevent extracted features from being utilized to reconstruct raw images and infer private attributes,
                    while retaining the useful information for the intended cloud service (i.e., image classification).
                    DeepObfuscator includes a learnable encoder,  namely,  obfuscator  that  is  designed  to  hide  privacy-related sensitive information from the features by performing our proposed adversarial training algorithm.
                    The proposed algorithm is designed by simulating the game between an attacker who makes efforts to reconstruct raw images and infer private attributes from the extracted features
                    and a defender who aims to protect user privacy.
                    Our experiments on CelebA dataset show that the quality of the reconstructed images from the obfuscated features of the raw image is dramatically decreased
                    from 0.9458 to 0.3175 in terms of multi-scale structural similarity (MS-SSIM).
                    The person in the reconstructed image, hence, becomes hardly to be re-identified.
                    The classification accuracy of the inferred private attributes that can be achieved by the attacker drops down to a random-guessing level, e.g.,
                    the accuracy of gender is reduced from 97.36&#37; to 58.85&#37;.
                    As a comparison, the accuracy of the intended classification tasks performed via the cloud service drops by only 2&#37;.
                    </div>
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Fatemehsadat Mireshghallah, Mohammadkazem Taram, Prakash Ramrakhyani, Dean Tullsen and Hadi Esmaeilzadeh
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs11" class="paper-title">
                        Shredder: Learning Noise Distributions to Protect Inference Privacy
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1905.11814" class="link-paper">[arxiv]</a>
                    </div>
                    <!-- <div id="abs11" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Jinshuo Dong, Aaron Roth and Weijie Su
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs12" class="paper-title">
                        Gaussian Differential Privacy <font color="#d07200"><b>(contributed talk)</b></font>
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1905.02383" class="link-paper">[arxiv]</a>
                    </div>
                    <!-- <div id="abs12" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Andres Munoz, Umar Syed, Sergei Vassilvitskii and Ellen Vitercik
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs13" class="paper-title">
                        Private Linear Programming Without Constraint Violations
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs13" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Hafiz Imtiaz, Jafar Mohammadi and Anand D. Sarwate
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs14" class="paper-title">
                        Correlation-Assisted Distributed Differentially Private Estimation
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1904.10059" class="link-paper">[arxiv]</a>
                    </div>
                    <!-- <div id="abs14" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Naoise Holohan, Stefano Braghin, Pol Mac Aonghusa and Killian Levacher
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs15" class="paper-title">
                        Diffprivlib: The IBM Differential Privacy Library
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1907.02444" class="link-paper">[arxiv]</a>
                    </div>
                    <!-- <div id="abs15" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Antti Koskela, Joonas Jälkö and Antti Honkela
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs16" class="paper-title">
                        Computing Exact Guarantees for Differential Privacy
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1906.03049" class="link-paper">[arxiv]</a>
                    </div>
                    <!-- <div id="abs16" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Joonas Jälkö, Antti Honkela and Samuel Kaski
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs17" class="paper-title">
                        Privacy-Preserving Data Sharing via Probabilistic Modelling
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs17" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Nitin Agrawal, Ali Shahin Shamsabadi, Matthew Kusner and Adria Gascon
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs18" class="paper-title">
                        QUOTIENT: Two-Party Secure Neural Network Training and Prediction
                        <font color="#d07200"><b>(contributed talk)</b></font>
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/pdf/1907.03372.pdf" class="link-paper">[arxiv]</a>
                    </div>
                    <!-- <div id="abs18" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Dingfan Chen, Ning Yu, Yang Zhang and Mario Fritz
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs19" class="paper-title">
                        GAN-Leaks: A Taxonomy of Membership Inference Attacks against GANs
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs19" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Si Kai Lee, Luigi Gresele, Mijung Park and Krikamol Muandet
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs20" class="paper-title">
                        Private Causal Inference using Propensity Scores
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1905.12592" class="link-paper">[arxiv]</a>
                    </div>
                    <!-- <div id="abs20" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Kareem Amin, Matthew Joseph and Jieming Mao
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs21" class="paper-title">
                        Pan-Private Uniformity Testing <font color="#d07200"><b>(contributed talk)</b></font>
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1911.01452" class="link-paper">[arxiv]</a>
                    </div>
                    <!-- <div id="abs21" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Ios Kotsogiannis, Yuchao Tao, Xi He, Ashwin Machanavajjhala, Michael Hay and Gerome Miklau
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs22" class="paper-title">
                        PrivateSQL: A Differentially Private SQL Query Engine
                        </a> &nbsp;&nbsp;
                        <a href="http://www.vldb.org/pvldb/vol12/p1371-kotsogiannis.pdf" class="link-paper">[arxiv]</a>
                    </div>
                    <!-- <div id="abs22" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Chao Jin, Ahmad Qaisar Ahmad Al Badawi, Balagopal Unnikrishnan, Jie Lin, Fook Mun Chan, James Brown, J. Peter Campbell, Michael F. Chiang, Jayashree Kalpathy-Cramer, Vijay Chandrasekhar, Pavitra Krishnaswamy and Khin Mi Mi Aung
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs23" class="paper-title">
                        CareNets: Efficient Homomorphic CNN for High Resolution Images
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs23" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Alexandra Schofield, Gregory Yauney and David Mimno
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs24" class="paper-title">
                        Combatting The Challenges of Local Privacy for Distributional Semantics with Compression
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs24" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Vitaly Feldman, Tomer Koren and Kunal Talwar
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs25" class="paper-title">
                        Private Stochastic Convex Optimization: Optimal Rates in Linear Time
                        <font color="#d07200"><b>(contributed talk)</b></font>
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs25" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Amrita Roy Chowdhury, Chenghong Wang, Xi He, Ashwin Machanavajjhala and Somesh Jha
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs26" class="paper-title">
                        Crypt&#949;: Crypto-Assisted Differential Privacy on Untrusted Servers
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs26" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Jiaming Xu and Dana Yang
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs27" class="paper-title">
                        Optimal Query Complexity of Private Sequential Learning
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1909.09836" class="link-paper">[arxiv]</a>
                    </div>
                    <!-- <div id="abs27" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Benjamin Spector, Andrew Tomkins and Ravi Kumar
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs28" class="paper-title">
                        Preventing Adversarial Use of Datasets through Fair Core-set Construction
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1910.10871" class="link-paper">[arxiv]</a>
                    </div>
                    <!-- <div id="abs28" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Nhathai Phan, My Thai, Devu Shila and Ruoming Jin
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs29" class="paper-title">
                        Differentially Private Lifelong Learning
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs29" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Alessandro Epasto, Hossein Esfandiari, Vahab Mirrokni, Andreas Munoz Medina, Umar Syed and Sergei Vassilvitskii
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs30" class="paper-title">
                        Anonymizing List Data
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs30" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Mimansa Jaiswal and Emily Mower Provost
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs31" class="paper-title">
                        Privacy Enhanced Multimodal Neural Representations for Emotion Recognition
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1910.13212" class="link-paper">[arxiv]</a>
                    </div>
                    <!-- <div id="abs31" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Mrinank Sharma, Michael Hutchinson, Siddharth Swaroop, Antti Honkela and Richard Turner
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs32" class="paper-title">
                        Differentially Private Federated Variational Inference
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1911.10563" class="link-paper">[arxiv]</a>
                    </div>
                    <!-- <div id="abs32" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Hassan Takabi, Robert Podschwadt, Jeff Druce, Curt Wu and Kevin Procopio
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs33" class="paper-title">
                        Privacy preserving Neural Network Inference on Encrypted Data with GPUs
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs33" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Casey Meehan and Kamalika Chaudhuri
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs34" class="paper-title">
                        Location Trace Privacy Under Conditional Priors
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs34" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Zhengli Zhao, Nicolas Papernot, Sameer Singh, Neoklis Polyzotis and Augustus Odena
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs35" class="paper-title">
                        Improving Differentially Private Models via Active Learning
                        </a> &nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1910.01177" class="link-paper">[arxiv]</a>
                    </div>
                    <!-- <div id="abs35" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Hsiang Hsu, Shahab Asoodeh and Flavio Calmon
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs36" class="paper-title">
                        Discovering Information-Leaking Samples and Features
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs36" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Martine De Cock, Rafael Dowsley, Anderson Nascimento, Davis Railsback, Jianwei Shen and Ariel Todoki
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs37" class="paper-title">
                        Fast Secure Logistic Regression for High Dimensional Gene Data
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs37" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Giuseppe Vietri, Grace Tian, Mark Bun, Thomas Steinke and Steven Wu
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs38" class="paper-title">
                        New Oracle-Efficient Algorithms for Private Synthetic Data Release
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs38" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Abraham Flaxman
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs39" class="paper-title">
                        Empirical quantification of privacy loss with examples relevant to the 2020 US Census
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs39" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Shadi Rahimian, Tribhuvanesh Orekondy and Mario Fritz
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs40" class="paper-title">
                        Differential Privacy Defenses and Sampling Attacks for Membership Inference
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs40" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Julius Adebayo
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs41" class="paper-title">
                        Tensions Between Differential Privacy and Local Explanations for Deep Neural Networks
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs41" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
                <div class="panel panel-default panel-paper">
                    <div class="panel-body panel-paper-body">
                        <span class="paper-author">
                        Amos Beimel, Aleksandra Korolova, Kobbi Nissim, Or Sheffet and Uri Stemmer
                        </span>
                        <br />
                        <a data-toggle="collapse" href="#abs42" class="paper-title">
                        The Power of Synergy in Differential Privacy: Combining a Small Curator with Local Randomizers
                        </a> &nbsp;&nbsp;
                        <!-- <a href="https://arxiv.org" class="link-paper">[arxiv]</a> -->
                    </div>
                    <!-- <div id="abs42" class="panel-footer panel-paper-footer collapse">
                    ABSTRACT
                    </div> -->
                </div>
        </div>
        </div>
    </section>


    <!-- Call for travel grants -->
    <!--
        <section id="grants" class="container content-section text-center">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2">
                    <h2>Travel Grants</h2>
                    <p>
                    Thanks to our generous sponsors, we are able to provide a limited number of travel grants of up to $800 to help partially cover the expenses of authors of accepted papers who have not received other travel support from NeurIPS this year.
                    To apply, please send an email to <a href="mailto:ppml18@easychair.org?Subject=PPML18%20Travel%20Grant%20Application">ppml18@easychair.org</a> with the subject “PPML18 Travel Grant Application” including your resume and a half-page statement of purpose mentioning the title and the authors of your accepted paper and a summary of anticipated travel expenses. If you are an undergraduate or graduate student, we ask for a half-page recommendation letter supporting your application to be sent to us by the deadline. The deadline for applications is <b>November 11, 2018 (11:59pm AoE)</b>. The notifications will be sent by <b>November 16</b>. Please feel free to send us an email if you have any questions.
                </div>
            </div>
        </section>
    -->

    <!-- Organizers Section -->
    <section id="organizers" class="content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>Organization</h2>
                <br />
                <h3>Workshop organizers</h3>
                <ul class="list-group">
                    <li class="list-group-item organizer">Borja Balle (DeepMind)</li>
                    <li class="list-group-item organizer">Kamalika Chaudhuri (UC San Diego)</li>
                    <li class="list-group-item organizer">Antti Honkela (University of Helsinki)</li>
                    <li class="list-group-item organizer">Antti Koskela (University of Helsinki)</li>
                    <li class="list-group-item organizer">Casey Meehan (UC San Diego)</li>
                    <li class="list-group-item organizer">Mijung Park (Max Planck Institute for Intelligent Systems)</li>
                    <li class="list-group-item organizer">Mary Anne Smart (UC San Diego)</li>
                    <li class="list-group-item organizer">Adrian Weller (Alan Turing Institute & Cambridge)</li>
                </ul>
                <br />
                <h3>Program Committee</h3>
                <ul class="list-group">
                  <li class="list-group-item organizer">James Bell (University of Cambridge)</li>
                  <li class="list-group-item organizer">Aurélien Bellet (INRIA)</li>
                  <li class="list-group-item organizer">Mark Bun (Boston University)</li>
                  <li class="list-group-item organizer">Christos Dimitrakakis (Chalmers University / University of Lille / Harvard University)</li>
                  <li class="list-group-item organizer">James Foulds (University of Maryland, Baltimore County)</li>
                  <li class="list-group-item organizer">Matt Fredrikson (Carnegie Mellon University)</li>
                  <li class="list-group-item organizer">Marco Gaboardi (University at Buffalo, SUNY)</li>
                  <li class="list-group-item organizer">Adria Gascon (The Alan Turing Institute / Warwick University)</li>
                  <li class="list-group-item organizer">Alon Gonen (Princeton University)</li>
                  <li class="list-group-item organizer">Peter Kairouz (Google AI)</li>
                  <li class="list-group-item organizer">Gautam Kamath (University of Waterloo)</li>
                  <li class="list-group-item organizer">Marcel Keller (Data61)</li>
                  <li class="list-group-item organizer">Nadin Kokciyan (King's College London)</li>
                  <li class="list-group-item organizer">Aleksandra Korolova (University of Southern California)</li>
                  <li class="list-group-item organizer">Audra McMillan (Boston University and Northeastern University)</li>
                  <li class="list-group-item organizer">Olga Ohrimenko (Microsoft)</li>
                  <li class="list-group-item organizer">Jun Sakuma (University of Tsukuba)</li>
                  <li class="list-group-item organizer">Anand Sarwate (Rutgers University)</li>
                  <li class="list-group-item organizer">Phillipp Schoppmann (Humboldt University of Berlin)</li>
                  <li class="list-group-item organizer">Or Sheffet (University of Alberta)</li>
                  <li class="list-group-item organizer">Kana Shimizu (Computational Biology Research Center, AIST)</li>
                  <li class="list-group-item organizer">Thomas Steinke (IBM)</li>
                  <li class="list-group-item organizer">Kunal Talwar (Google)</li>
                  <li class="list-group-item organizer">Carmela Troncoso (Ecole Polytechnique Fédérale de Lausanne)</li>
                  <li class="list-group-item organizer">Yu-Xiang Wang (Carnegie Mellon University)</li>
                  <li class="list-group-item organizer"></li>
                </ul>
                <!-- <br />
                <h3>Sponsors</h3>
                <br />
                    <img style="margin:50px;"height="80" src="img/ati-white.png"> -->
                    <!-- <img style="margin:50px;"height="80" src="img/amazon.png">
                    <img style="margin:50px;"height="80" src="img/google.png">
                    <img style="margin:50px;"height="80" src="img/microsoft.png"> -->
            </div>
        </div>
    </section>

    <!-- Accessibility Section -->
    <section id="access" class="content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>Accessibility</h2>
                <br />
                <p>
                  By taking a few simple steps&mdash;such as paying special attention to font sizes and captions&mdash;
                  you can make your
                  <a href="https://www.washington.edu/doit/how-can-you-make-your-presentation-accessible">presentations</a> and
                  <a href="resources/accessibility_posters_gilson2019.pdf">posters</a>
                  more accessible.
                  Feel free to <a href="mailto:priml2019@easychair.org">contact us</a> about any accessibility concerns relating to the website, workshop, etc.
                </p>
                <br />
                <br />
                <br />
                <br />
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <div class="container text-center" >
          <p>Sponsored by</p>
            <a href="https://www.turing.ac.uk/"><img height="50" style="margin:30px;" src="img/ati-white.png"></a>
            <a class="hide-on-mobile" href="http://lcfi.ac.uk/"><img height="50" style="margin:20px;" src="img/cfi.jpg"></a>
            <a class="mobile-only" href="http://lcfi.ac.uk/"><img width="275" style="margin:10px;" src="img/cfi.jpg"></a>
            <a href="https://deepmind.com/"><img height="50" style="margin:30px;" src="img/DM.png"></a>
        </div>
        <div class="container text-center">
            <p>Contact us: <a href="mailto:priml2019@easychair.org">priml2019@easychair.org</a></p>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="js/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>

    <!-- Theme JavaScript -->
    <script src="js/script.js"></script>

</body>

</html>
